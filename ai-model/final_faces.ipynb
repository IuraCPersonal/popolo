{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nEG4DighzIC"
   },
   "outputs": [],
   "source": [
    "# Important imports\n",
    "import torch\n",
    "import cv2\n",
    "from torch import nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moviepy.editor as mp\n",
    "from PIL import Image, ImageFilter\n",
    "from google.colab.patches import cv2_imshow\n",
    "from torchvision import transforms,models\n",
    "from moviepy.editor import VideoFileClip \n",
    "\n",
    "\n",
    "#Choosing devide to be gpu if have one, else cpu\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzLfgutSh7EI",
    "outputId": "8990b2c4-e822-4301-a7fd-74fccb799f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# connect to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2omGR6Lh-yF"
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjVP-7TaiFBW"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = torchvision.models.resnet101(pretrained = True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    nr_feat = model.fc.in_features \n",
    "    model.fc = nn.Sequential(OrderedDict([('fc',nn.Linear(nr_feat,1)),('sigmoid',nn.Sigmoid())]))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOgSUb0qiHCy",
    "outputId": "87d4885c-4471-4694-f797-ab9d5157421a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "\n",
    "loaded_model = get_model()a\n",
    "loaded_model.load_state_dict(torch.load(r'/content/drive/MyDrive/CVproject/resnet101_classificator.pth'), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTjxmdW_iNcV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load our serialized model and parameter from disk\n",
    "modelFile = \"/content/drive/MyDrive/CVproject/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"/content/drive/MyDrive/CVproject/deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# load the input video and construct an input blob\n",
    "# for the video by resizing to a fixed 300x300 pixels \n",
    "# and the normalizing it\n",
    "# df = pd.DataFrame(columns=['frame', 'x_min', 'y_min', 'x_max', 'y_max'])\n",
    "cap = cv2.VideoCapture('/content/drive/MyDrive/CVproject/kids.mp4')\n",
    "\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('output_kids.mp4', cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        # img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "        height, width = img.shape[:2]\n",
    "        img1 = img.copy()\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # create blob from image\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)),1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "        # print(\"First Blob: {}\".format(blob.shape))\n",
    "        # pass the blob through the network and obtain the detections and predictions\n",
    "        net.setInput(blob)\n",
    "        faces = net.forward()\n",
    "\n",
    "        # loop over the detections(faces)\n",
    "        for i in range(faces.shape[2]):\n",
    "            # extract the confidence (i.e. probability) associeted with the prediction\n",
    "            confidence = faces[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections by ensuring the `confidence` is greater than\n",
    "            # the minimum confidence\n",
    "            if confidence > 0.5:\n",
    "                # compute the (x, y) - coordinates of the bounding box for the object\n",
    "                box = faces[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "                current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "                # new_row = {'frame': current_frame, 'x_min': x, 'y_min': y, 'x_max': x1, 'y_max': y1}\n",
    "                # df = df.append(new_row, ignore_index=True)\n",
    "            \n",
    "                a = (img[y:y1, x:x1]) \n",
    "            # cv2_imshow(a)\n",
    "                PIL_image = Image.fromarray(a)\n",
    "                tensor = transformations(PIL_image)\n",
    "                prediction = loaded_model(tensor.unsqueeze(0))\n",
    "                \n",
    "                if float(prediction) > .5:\n",
    "          # cv2.rectangle(img1, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "                  face_image = Image.fromarray(img1)\n",
    "                  cropped_image = face_image.crop((x, y, x1, y1))\n",
    "                  blurred_image = cropped_image.filter(ImageFilter.GaussianBlur(radius=15))\n",
    "                  face_image.paste(blurred_image, (x, y, x1, y1))\n",
    "                  img1 = np.array(face_image)\n",
    "\n",
    "      # cv2_imshow(img1)\n",
    "        out.write(img1)\n",
    "\n",
    "        # cv2_imshow(img1)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# print(df)         \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsPGNYHjiPYR",
    "outputId": "04c0a021-f20e-4f4a-c250-047cc30aeef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video final_video_kids.mp4\n",
      "[MoviePy] Writing audio in final_video_kidsTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:00<00:00, 716.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video final_video_kids.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 259/259 [00:05<00:00, 45.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: final_video_kids.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap = VideoFileClip(\"/content/drive/MyDrive/CVproject/kids.mp4\")\n",
    "audio = cap.audio\n",
    "out = VideoFileClip(\"/content/output_kids.mp4\")\n",
    "final_video = out.set_audio(audio)\n",
    "final_video.write_videofile(\"final_video_kids.mp4\", fps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bgZyDk8jrmO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_faces",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
